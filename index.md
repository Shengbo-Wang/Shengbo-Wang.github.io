---
title: Shengbo Wang
permalink: /
layout: default
---
# Short Bio
I am currently a fourth-year Ph.D. candidate in Operations Research within the Department of [Management Science and Engineering (MS&E)](https://msande.stanford.edu/) at Stanford University. I am fortunate to be co-advised by Prof. [Peter Glynn](https://web.stanford.edu/~glynn/) and Prof. [Jose Blanchet](https://web.stanford.edu/~jblanche/). Prior to my doctoral studies at Stanford, I completed my B.S. degree at Cornell Engineering, where I majored in [Operations Research and Information Engineering (ORIE)](https://www.orie.cornell.edu/orie). 

# Research Interests
I am broadly interested in research areas centered around applied probability, stochastic modeling, and simulation. My work focuses on designing and analyzing algorithms dedicated to the learning and control of dynamic engineering systems. Key areas of my research include:
* Designing and implementing sample-efficient estimators capable of learning key system characteristics. 
* Establishing optimal sample complexities for the learning and control of mixing Markov systems.
* Conceptualizing and implementing modeling frameworks that ensure the reliable control of dynamic engineering systems, leveraging distributionally robust optimization. 
* Exploring methodologies that can efficiently learn and apply reliable control to dynamic engineering systems using reinforcement learning (RL). 

# Publications & Preprints
## Conference Papers
[A Finite Sample Complexity Bound for Distributionally Robust Q-learning](https://arxiv.org/abs/2302.13203)
* Shengbo Wang, Nian Si, Jose Blanchet, Zhengyuan Zhou.
* Artificial Intelligence and Statistics Conference (AISTATS) 2023.

[Optimal Sample Complexity for Average Reward Markov Decision Processes](https://arxiv.org/abs/2310.08833)
* Shengbo Wang, Jose Blanchet, Peter Glynn.
* International Conference on Learning Representations (ICLR) 2024.

## Preprints 
[Sample Complexity of Variance-reduced Distributionally Robust Q-learning](https://arxiv.org/abs/2305.18420)
* Shengbo Wang, Nian Si, Jose Blanchet, Zhengyuan Zhou. 

[Optimal Sample Complexity of Reinforcement Learning for Mixing Discounted Markov Decision Processes](https://arxiv.org/abs/2302.07477)
* Shengbo Wang, Jose Blanchet, Peter Glynn.

[On the Foundation of Distributionally Robust Reinforcement Learning](https://arxiv.org/abs/2311.09018) 
* Shengbo Wang, Nian Si, Jose Blanchet, Zhengyuan Zhou. 

Derivative Estimation for Expectations of Additive Functionals of Jump Diffusions
* Shengbo Wang, Jose Blanchet, Peter Glynn. 
* Working Paper. 

Exact Exponential Tail Asymptotics of Markov Chain Additive Functionals Stopped at a Hitting Time 
* Shengbo Wang, Jose Blanchet, Peter Glynn. 
* Working Paper.


# Presentations 
On the Foundation of Distributionally Robust Reinforcement Learning
* Conference on Information Sciences and Systems (CISS) 2024.
* 14/Mar/2024

Reinforcement Learning for Mixing Systems 
* Presented at INFORMS 2023. 

Distributionally Robust Q-learning: Formulations, Algorithms, and Sample Complexities 
* Presented at SIAMOP 2023. 

Distributionally Robust Q-learning: Algorithm Designs and Sample Complexities 
* Presented at Stanford OR Seminar. 

A Finite Sample Complexity Bound for the Distributionally Robust Q-learning
* Presented at INFORMS 2022.